{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjJKKKkR1+DH9v71hZfpjR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttury/Do_It_For_Deep-Learning/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x0UTKVqrla0"
      },
      "source": [
        "# data set prepare\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "print(cancer.data.shape, cancer.target.shape) # 569개의 샘플, 30개의 특성\n",
        "print()\n",
        "print(cancer.data[:3])\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKiWmildul37"
      },
      "source": [
        "# checking feature by box plot\n",
        "\n",
        "plt.boxplot(cancer.data) # 박스플롯 그래프(중앙값으로부터 벗어난 정도)\n",
        "plt.xlabel('feature')\n",
        "plt.ylabel('value')\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "print(cancer.feature_names[[3, 13, 23]]) # 분포가 큰 특성 살피기\n",
        "print(np.unique(cancer.target, return_counts = True)) # 타겟 데이터의 양성/음성 개수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMZraQl7wsv6"
      },
      "source": [
        "# spliting training data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42) # 훈련 데이터 세트 나누기, stratify는 클래스 비율이 불균형한 경우에 사용\n",
        "print(x_train.shape, x_test.shape) # 1:4 비율\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AjKByfKybM6"
      },
      "source": [
        "# ndarray\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([3, 4, 5])\n",
        "\n",
        "print(a + b)\n",
        "print(a * b)\n",
        "print(np.sum(a * b))\n",
        "print()\n",
        "\n",
        "print(np.zeros(5))\n",
        "print(np.ones((3, 4))) # 다차원 배열을 만들 때는 튜플 사용\n",
        "print(np.full((5, 5), 7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdcn_Pi_yJDC"
      },
      "source": [
        "class LogisticNeuron:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.w = None\n",
        "    self.b = None\n",
        "\n",
        "  def forpass(self, x_i):\n",
        "    z = np.sum(self.w * x_i) + self.b # 하나의 값\n",
        "    return z\n",
        "\n",
        "  def backprop(self, x_i, err):\n",
        "    w_grad = x_i * err # 30차원 벡터\n",
        "    b_grad = 1 * err # 하나의 값\n",
        "    return w_grad, b_grad\n",
        "\n",
        "  def activation(self, z):\n",
        "    z = np.clip(z, -100, None)\n",
        "    a = 1 / (1 + np.exp(-z)) # 시그모이드 계산\n",
        "    return a\n",
        "\n",
        "  def fit(self, x, y, epochs=100):\n",
        "    self.w = np.ones(x.shape[1]) # 30차원(특성 개수) 벡터를 가중치로 설정\n",
        "    self.b = 0\n",
        "    for _ in range(epochs):\n",
        "      for x_i, y_i in zip(x, y):\n",
        "        z = self.forpass(x_i) # 정방향 계산\n",
        "        a = self.activation(z) # 활성화 함수 적용\n",
        "        err = -(y_i - a) # 오차 계산\n",
        "        w_grad, b_grad = self.backprop(x_i, err) # 역방향 계산\n",
        "        self.w -= w_grad # 30차원 벡터끼리 연산\n",
        "        self.b -= b_grad # 단일 수끼리 연산\n",
        "    \n",
        "  def predict(self, x):\n",
        "    z = [self.forpass(x_i) for x_i in x] # 569(샘플 수)차원 벡터\n",
        "    a = self.activation(np.array(z)) # 569차원 벡터\n",
        "    return a > 0.5 # 1 또는 0 반환\n",
        "\n",
        "neuron = LogisticNeuron()\n",
        "neuron.fit(x_train, y_train)\n",
        "\n",
        "print(np.mean(neuron.predict(x_test) == y_test)) # accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPkMWNS52Vm7"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = SGDClassifier(loss = 'log', max_iter = 100, tol = 1e-3, random_state = 42)\n",
        "'''\n",
        "loss : 손실 함수 설정, log는 로지스틱 손실 함수\n",
        "tol : 에포크마다 tol에 지정한 값만큼 손실 함수가 감소되지 않으면 반복 종료\n",
        "max_iter : 반복 횟수, 에포크 개수\n",
        "'''\n",
        "\n",
        "sgd.fit(x_train, y_train)\n",
        "print(sgd.score(x_test, y_test))\n",
        "print(sgd.predict(x_test[0:10])) # 입력 데이터로 2차원 배열만 받아들임"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}